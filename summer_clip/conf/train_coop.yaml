defaults:
  - hydra_setup
  - meta_setup
  - _self_
  - dataset: tip_eurosat_train_no_image
  - dataset@val_dataset: tip_eurosat_test_no_image
  - prompting: tip_eurosat
  - saved_paths: clip_paths

clip:
  model_name: RN50
  image_features_path: ${saved_paths.image_features.EuroSAT_tip_train-RN50}
  val_image_features_path: ${saved_paths.image_features.EuroSAT_tip_test-RN50}

clip_gpt:
  meta_cfg_path: /home/myurachinskiy/CLIP/summer-clip/outputs/2023-02-02/22-43-01/checkpoints/epoch_4/step_222605/model_cfg.yaml
  state_dict_path: /home/myurachinskiy/CLIP/summer-clip/outputs/2023-02-02/22-43-01/checkpoints/epoch_4/step_222605/model.ckpt

# prompt_model:
#   _target_: summer_clip.clip_prompt.prompt_models.CoOp
#   prompt_len: 16
#   dist_p: 2

prompt_model:
  _target_: summer_clip.clip_prompt.prompt_models.Gumbelv1a1
  prompt_len: 5
  temp_scheduler:
    _target_: summer_clip.clip_prompt.temp_schedulers.ConstantScheduler
    val: 1.

# prompt_model:
#   _target_: summer_clip.clip_prompt.prompt_models.Gumbelv3a1
#   prompt_len: 5
#   hidden_dim: 256
#   temp_scheduler:
#     _target_: summer_clip.clip_prompt.temp_schedulers.ConstantScheduler
#     val: 1.

tokenizer:
  path: transformers.CLIPTokenizer
  name: openai/clip-vit-base-patch32  # should not differ from large
  set_pad_as_eos: false
  tokenize_classes_kwargs: {}

optim:
  weight_decay: 0.0005
  optim_class: torch.optim.SGD
  kwargs:
    lr: 0.002
    momentum: 0.9
    dampening: 0
    nesterov: false

# optim:
#   weight_decay: 0.0005
#   optim_class: torch.optim.Adam
#   kwargs:
#     lr: 0.002

scheduler:
  name: cosine
  warmup_part: 0.005

data_loader:
  train:
    batch_size: 32
    shuffle: true
    pin_memory: true
    num_workers: 0
  val:
    batch_size: 32
    shuffle: true
    pin_memory: true
    num_workers: 0

dataset_info:
  k_shots: 16

collator:
  _target_: summer_clip.clip_prompt.prompt_learner.LeftPromptCollator
  clip_seq_len: 77

text_batcher:
  path: summer_clip.clip_prompt.prompt_learner.ImageTextBatcher
  kwargs: {}

# vocab_filter:
#   path: summer_clip.clip_prompt.vocab_filters.AllowedTokensFilter
#   kwargs:
#     allowed_tokens: ['a</w>', 'centered</w>', 'satellite</w>', 'photo</w>', 'of</w>']

# vocab_filter:
#   path: summer_clip.clip_prompt.vocab_filters.NoFilter
#   kwargs: {}

# vocab_filter:
#   path: summer_clip.clip_prompt.vocab_filters.FilterNonBasicStrong
#   kwargs:
#     keep_english: true
#     keep_numbers: true
#     keep_punctuation: true

vocab_filter:
  path: summer_clip.clip_prompt.vocab_filters.PromptsUnionFilter
  kwargs:
    prompts_paths:
      - /home/myurachinskiy/CLIP/summer-clip/summer_clip/conf/prompting/imagenet.yaml
    classes_paths: 
      - /home/myurachinskiy/CLIP/summer-clip/summer_clip/conf/prompting/tip_eurosat.yaml

loss:
  clip: 1.0
  fluency: 0.

lm_loss:
  _target_: summer_clip.clip_prompt.prompt_learner.SuffixLMLoss
  prompt_len: ${prompt_model.prompt_len}

# lm_loss:
#   _target_: summer_clip.clip_prompt.prompt_learner.FullLMLoss

training:
  epochs_num: 200
  info_steps: 1
  gradient_accumulation_steps: 1
  classes_batch_size: 16
  new_top_prompts_each_epoch: false
  prompts_table_update_epochs: 50
  checkpoints_dir: checkpoints/

log:
  calculate_every: 1

exp:
  project: train_clip_coop
  name: coop_v1
