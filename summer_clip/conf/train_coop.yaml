defaults:
  - hydra_setup
  - meta_setup
  - _self_
  - dataset: tip_eurosat_train_no_image
  - dataset@val_dataset: tip_eurosat_test_no_image
  - prompting: tip_eurosat
  - saved_paths: clip_paths

clip:
  model_name: RN50
  image_features_path: ${saved_paths.image_features.EuroSAT_tip_train-RN50}
  val_image_features_path: ${saved_paths.image_features.EuroSAT_tip_test-RN50}

clip_gpt:
  meta_cfg_path: /home/myurachinskiy/CLIP/summer-clip/outputs/2023-02-02/22-43-01/checkpoints/epoch_4/step_222605/model_cfg.yaml
  state_dict_path: /home/myurachinskiy/CLIP/summer-clip/outputs/2023-02-02/22-43-01/checkpoints/epoch_4/step_222605/model.ckpt

tokenizer:
  path: transformers.CLIPTokenizer
  name: openai/clip-vit-base-patch32  # should not differ from large
  set_pad_as_eos: false
  tokenize_classes_kwargs: {}

prompt:
  len: 16

optim:
  weight_decay: 0.0005
  optim_class: torch.optim.SGD
  kwargs:
    lr: 0.002
    momentum: 0.9
    dampening: 0
    nesterov: false

scheduler:
  name: cosine
  warmup_part: 0.005

data_loader:
  train:
    batch_size: 32
    shuffle: true
    pin_memory: true
    num_workers: 0
  val:
    batch_size: 32
    shuffle: true
    pin_memory: true
    num_workers: 0

dataset_info:
  k_shots: 16

collator:
  _target_: summer_clip.clip_prompt.prompt_learner.LeftPromptCollator
  clip_seq_len: 77

text_batcher:
  path: summer_clip.clip_prompt.prompt_learner.ImageTextBatcher
  kwargs: {}

loss:
  clip: 1.0
  fluency: 0.

lm_loss:
  _target_: summer_clip.clip_prompt.prompt_learner.SuffixLMLoss
  prompt_len: ${prompt.len}

training:
  epochs_num: 200
  info_steps: 1
  gradient_accumulation_steps: 1
  classes_batch_size: 16
  new_top_prompts_each_epoch: false
  checkpoints_dir: checkpoints/

log:
  calculate_every: 1

exp:
  project: train_clip_coop
  name: coop_v1
