defaults:
  - hydra_setup
  - meta_setup
  - _self_
  - dataset: imagenet_train_no_image
  - prompting: tip_imagenet
  - saved_paths: clip_paths

clip:
  model_name: RN50
  image_features_path: ${saved_paths.image_features.ImageNet_train-RN50}

tokenizer:
  path: transformers.CLIPTokenizer
  # path: transformers.GPT2Tokenizer
  name: openai/clip-vit-base-patch32  # should not differ from large
  # name: gpt2-large
  set_pad_as_eos: false
  tokenize_classes_kwargs: {}
    # add_prefix_space: true

model:
  use_clip_gpt: true
  meta_cfg_path: /home/myurachinskiy/CLIP/summer-clip/outputs/2023-02-02/22-43-01/checkpoints/epoch_4/step_222605/model_cfg.yaml
  state_dict_path: /home/myurachinskiy/CLIP/summer-clip/outputs/2023-02-02/22-43-01/checkpoints/epoch_4/step_222605/model.ckpt

# prompt_model:
#   _target_: summer_clip.clip_prompt.prompt_learner.FluentPromptModel
#   model_cfg:
#     cdist_kwargs: {}

prompt_model:
  _target_: summer_clip.clip_prompt.autoprompt_learner.AutoPromptModel
  model_cfg:
    num_cands: 16
    search_steps: 1

# init_prompter:
#   _target_: summer_clip.clip_prompt.prompt_learner.InitNumTokensPrompter
#   token: <|startoftext|>
#   length: 5

init_prompter:
  _target_: summer_clip.clip_prompt.prompt_learner.InitRandomPrompter
  length: 16

text_batcher:
  path: summer_clip.clip_prompt.prompt_learner.ImageTextBatcher
  kwargs: {}

data_loader:
  train:
    batch_size: 6
    shuffle: true
    pin_memory: true
    num_workers: 4

collator:
  _target_: summer_clip.clip_prompt.prompt_learner.LeftPromptCollator
  clip_seq_len: 77

loss:
  clip: 1.0
  fluency: 1.0

training:
  epochs_num: 1
  info_steps: 1
  save_steps: 20
  classes_batch_size: 8
  max_top_prompts: 50
  gradient_accumulation_steps: 1
  new_top_prompts_each_epoch: false
  checkpoints_dir: checkpoints/

log:
  calculate_every: 1

exp:
  project: train_clip_prompt
  name: prompt_v1
